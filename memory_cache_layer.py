#!/usr/bin/env python3
"""
ðŸ—ï¸ MODULE: Memory Cache Layer - In-Memory L1 Cache with LRU Eviction
====================================================================

ðŸ“‹ PURPOSE:
    In-memory L1 cache layer implementation with LRU eviction policy.
    Provides fast memory-based caching with automatic expiration and access tracking.

ðŸŽ¯ CORE FUNCTIONALITY:
    â€¢ In-memory cache with LRU (Least Recently Used) eviction policy
    â€¢ TTL-based automatic expiration with background cleanup
    â€¢ Thread-safe operations with fine-grained locking
    â€¢ Comprehensive cache statistics and utilization tracking

ðŸ”„ EDIT HISTORY (Last 5 Changes):
==================================================================
ðŸ“ 2025-08-23 10:15:00 | Agent C | ðŸ†• FEATURE
   â””â”€ Goal: Extract memory cache layer from advanced_caching_architecture.py via STEELCLAD
   â””â”€ Changes: Created dedicated module for in-memory L1 cache operations
   â””â”€ Impact: Clean separation of memory caching from Redis and orchestration layers

ðŸ·ï¸ METADATA:
==================================================================
ðŸ“… Created: 2025-08-23 by Agent C
ðŸ”§ Language: Python
ðŸ“¦ Dependencies: threading, time, pickle, logging, collections
ðŸŽ¯ Integration Points: Cache metrics tracker and caching orchestration
âš¡ Performance Notes: Optimized for high-throughput with minimal locking overhead
ðŸ”’ Security Notes: Thread-safe operations with automatic resource cleanup

ðŸ§ª TESTING STATUS:
==================================================================
âœ… Unit Tests: Pending | Last Run: N/A
âœ… Integration Tests: Pending | Last Run: N/A 
âœ… Performance Tests: Via caching system validation | Last Run: N/A
âš ï¸  Known Issues: None at creation

ðŸ“ž COORDINATION NOTES:
==================================================================
ðŸ¤ Dependencies: caching_models, cache_metrics_tracker
ðŸ“¤ Provides: High-performance in-memory caching for L1 cache operations
ðŸš¨ Breaking Changes: Initial creation - no breaking changes yet
"""

import time
import pickle
import logging
import threading
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
from collections import deque

# Import models
from caching_models import CacheConfig, CacheEntry, CacheLayer
from cache_metrics_tracker import CacheMetrics

class MemoryCacheLayer:
    """In-memory L1 cache layer with LRU eviction"""
    
    def __init__(self, config: CacheConfig, metrics: CacheMetrics):
        self.config = config
        self.metrics = metrics
        self.cache: Dict[str, CacheEntry] = {}
        self.access_order: deque = deque()
        self.max_size = config.max_memory_cache_size
        self._lock = threading.RLock()
        self.logger = logging.getLogger('MemoryCacheLayer')
    
    def get(self, key: str) -> Optional[Any]:
        """Get value from memory cache"""
        start_time = time.perf_counter()
        
        with self._lock:
            if key not in self.cache:
                response_time = (time.perf_counter() - start_time) * 1000
                self.metrics.record_miss(CacheLayer.MEMORY, response_time)
                return None
            
            entry = self.cache[key]
            
            # Check expiration
            if entry.is_expired:
                del self.cache[key]
                try:
                    self.access_order.remove(key)
                except ValueError:
                    pass
                response_time = (time.perf_counter() - start_time) * 1000
                self.metrics.record_miss(CacheLayer.MEMORY, response_time)
                return None
            
            # Update access metadata
            entry.update_access()
            
            # Move to end of access order (most recently used)
            try:
                self.access_order.remove(key)
            except ValueError:
                pass
            self.access_order.append(key)
            
            response_time = (time.perf_counter() - start_time) * 1000
            self.metrics.record_hit(CacheLayer.MEMORY, response_time)
            
            return entry.value
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """Set value in memory cache"""
        try:
            with self._lock:
                # Calculate size
                size_bytes = len(pickle.dumps(value))
                
                # Create cache entry
                entry = CacheEntry(
                    key=key,
                    value=value,
                    created_at=datetime.now(timezone.utc),
                    last_accessed=datetime.now(timezone.utc),
                    access_count=1,
                    ttl=ttl or self.config.default_ttl,
                    size_bytes=size_bytes,
                    layer=CacheLayer.MEMORY
                )
                
                # Evict if necessary
                while len(self.cache) >= self.max_size and self.access_order:
                    oldest_key = self.access_order.popleft()
                    if oldest_key in self.cache:
                        del self.cache[oldest_key]
                        self.metrics.record_eviction(CacheLayer.MEMORY)
                
                # Store entry
                self.cache[key] = entry
                
                # Update access order
                if key in self.access_order:
                    self.access_order.remove(key)
                self.access_order.append(key)
                
                # Record memory usage
                self.metrics.record_memory_usage(size_bytes, CacheLayer.MEMORY)
                
                return True
                
        except Exception as e:
            self.logger.error(f"Failed to set key {key} in memory cache: {e}")
            self.metrics.record_error(CacheLayer.MEMORY, "set_error")
            return False
    
    def delete(self, key: str) -> bool:
        """Delete key from memory cache"""
        with self._lock:
            if key in self.cache:
                del self.cache[key]
                try:
                    self.access_order.remove(key)
                except ValueError:
                    pass
                return True
            return False
    
    def clear(self) -> int:
        """Clear all entries from memory cache"""
        with self._lock:
            count = len(self.cache)
            self.cache.clear()
            self.access_order.clear()
            self.logger.info(f"Cleared {count} entries from memory cache")
            return count
    
    def evict_expired(self) -> int:
        """Evict all expired entries"""
        evicted_count = 0
        current_time = datetime.now(timezone.utc)
        
        with self._lock:
            expired_keys = []
            
            for key, entry in self.cache.items():
                if entry.is_expired:
                    expired_keys.append(key)
            
            for key in expired_keys:
                del self.cache[key]
                try:
                    self.access_order.remove(key)
                except ValueError:
                    pass
                evicted_count += 1
            
            if evicted_count > 0:
                self.metrics.record_eviction(CacheLayer.MEMORY, evicted_count)
                self.logger.debug(f"Evicted {evicted_count} expired entries")
        
        return evicted_count
    
    def get_stats(self) -> Dict[str, Any]:
        """Get memory cache statistics"""
        with self._lock:
            if not self.cache:
                return {
                    'total_entries': 0,
                    'total_size_bytes': 0,
                    'total_size_mb': 0,
                    'max_size': self.max_size,
                    'utilization': 0,
                    'oldest_entry_age': 0,
                    'average_access_count': 0
                }
            
            total_size = sum(entry.size_bytes for entry in self.cache.values())
            current_time = datetime.now(timezone.utc)
            
            # Calculate oldest entry age
            oldest_age = max((current_time - entry.created_at).total_seconds() 
                           for entry in self.cache.values())
            
            # Calculate average access count
            avg_access = sum(entry.access_count for entry in self.cache.values()) / len(self.cache)
            
            return {
                'total_entries': len(self.cache),
                'total_size_bytes': total_size,
                'total_size_mb': total_size / (1024 * 1024),
                'max_size': self.max_size,
                'utilization': len(self.cache) / self.max_size if self.max_size > 0 else 0,
                'oldest_entry_age': oldest_age,
                'average_access_count': avg_access,
                'access_order_length': len(self.access_order)
            }
    
    def get_top_accessed_keys(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get top accessed cache entries"""
        with self._lock:
            # Sort by access count descending
            sorted_entries = sorted(
                self.cache.items(), 
                key=lambda x: x[1].access_count, 
                reverse=True
            )
            
            return [
                {
                    'key': key,
                    'access_count': entry.access_count,
                    'age_seconds': entry.age_seconds,
                    'size_bytes': entry.size_bytes
                }
                for key, entry in sorted_entries[:limit]
            ]
    
    def resize_cache(self, new_max_size: int):
        """Resize the cache to a new maximum size"""
        with self._lock:
            old_size = self.max_size
            self.max_size = new_max_size
            
            # If new size is smaller, evict excess entries
            if new_max_size < len(self.cache):
                evictions_needed = len(self.cache) - new_max_size
                evicted = 0
                
                while evicted < evictions_needed and self.access_order:
                    oldest_key = self.access_order.popleft()
                    if oldest_key in self.cache:
                        del self.cache[oldest_key]
                        evicted += 1
                
                self.metrics.record_eviction(CacheLayer.MEMORY, evicted)
                self.logger.info(f"Resized cache from {old_size} to {new_max_size}, evicted {evicted} entries")
            else:
                self.logger.info(f"Resized cache from {old_size} to {new_max_size}")
    
    def warm_cache(self, key_value_pairs: Dict[str, Any]) -> int:
        """Warm cache with predefined key-value pairs"""
        warmed = 0
        
        for key, value in key_value_pairs.items():
            if self.set(key, value):
                warmed += 1
        
        self.logger.info(f"Cache warmed with {warmed}/{len(key_value_pairs)} entries")
        return warmed
    
    def get_cache_health(self) -> Dict[str, Any]:
        """Get cache health assessment"""
        stats = self.get_stats()
        
        # Calculate health metrics
        utilization = stats['utilization']
        
        health_score = 100
        status = "excellent"
        
        if utilization > 0.9:
            health_score -= 30
            status = "high_utilization"
        elif utilization > 0.8:
            health_score -= 15
            status = "good"
        
        # Check for old entries
        if stats['oldest_entry_age'] > 3600:  # 1 hour
            health_score -= 10
        
        if health_score < 50:
            status = "poor"
        elif health_score < 70:
            status = "fair"
        
        return {
            'health_score': health_score,
            'status': status,
            'utilization': utilization,
            'total_entries': stats['total_entries'],
            'recommendations': self._get_health_recommendations(stats)
        }
    
    def _get_health_recommendations(self, stats: Dict[str, Any]) -> List[str]:
        """Generate health recommendations based on cache statistics"""
        recommendations = []
        
        if stats['utilization'] > 0.9:
            recommendations.append("Consider increasing memory cache size")
        
        if stats['oldest_entry_age'] > 7200:  # 2 hours
            recommendations.append("Consider reducing TTL for better cache freshness")
        
        if stats['average_access_count'] < 2:
            recommendations.append("Low cache utilization - review caching strategy")
        
        return recommendations