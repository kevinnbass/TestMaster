#!/usr/bin/env python3
"""
Comprehensive test suite for TestMaster core modules
Generated by Agent D Phase 2 - Test Coverage Expansion
Coverage: Core framework, configuration, and essential components
"""

import pytest
import asyncio
import sys
import os
import json
import tempfile
import shutil
from unittest.mock import Mock, patch, MagicMock, AsyncMock
from typing import Dict, Any, List

# Add TestMaster to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import core modules with fallbacks
try:
    from TestMaster.core.framework_abstraction import FrameworkAbstraction
    from TestMaster.core.context_manager import ContextManager
    from TestMaster.core.shared_state import SharedState
    from TestMaster.core.tracking_manager import TrackingManager
    from TestMaster.core.feature_flags import FeatureFlags
    from TestMaster.config.unified_config import UnifiedConfig
except ImportError as e:
    print(f"Import warning: {e}")
    # Mock imports if modules don't exist yet
    FrameworkAbstraction = Mock
    ContextManager = Mock
    SharedState = Mock
    TrackingManager = Mock
    FeatureFlags = Mock
    UnifiedConfig = Mock


class TestFrameworkAbstraction:
    """Test the core framework abstraction layer"""
    
    def test_framework_abstraction_initialization(self):
        """Test FrameworkAbstraction initialization"""
        with patch('TestMaster.core.framework_abstraction.logging'):
            framework = FrameworkAbstraction()
            assert framework is not None
            assert hasattr(framework, 'supported_frameworks')
    
    def test_framework_detection(self):
        """Test automatic framework detection"""
        framework = FrameworkAbstraction()
        
        # Test pytest detection
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', mock_open_with_content('pytest')):
                detected = framework.detect_framework('test_project')
                assert 'pytest' in str(detected).lower()
    
    def test_test_file_generation(self):
        """Test test file generation for different frameworks"""
        framework = FrameworkAbstraction()
        
        test_cases = [
            {'framework': 'pytest', 'module': 'sample_module.py'},
            {'framework': 'unittest', 'module': 'another_module.py'},
            {'framework': 'nose2', 'module': 'third_module.py'}
        ]
        
        for case in test_cases:
            result = framework.generate_test_file(
                module_path=case['module'],
                framework=case['framework']
            )
            assert result is not None
            assert case['framework'] in str(result)
    
    def test_framework_compatibility_check(self):
        """Test framework compatibility checking"""
        framework = FrameworkAbstraction()
        
        compatible_frameworks = ['pytest', 'unittest', 'nose2', 'doctest']
        for fw in compatible_frameworks:
            assert framework.is_framework_supported(fw) == True
        
        # Test unsupported framework
        assert framework.is_framework_supported('invalid_framework') == False
    
    def test_cross_framework_test_conversion(self):
        """Test conversion between different test frameworks"""
        framework = FrameworkAbstraction()
        
        # Mock pytest test
        pytest_test = """
def test_sample_function():
    assert sample_function() == expected_result
"""
        
        # Convert to unittest
        unittest_result = framework.convert_test(
            pytest_test, 
            from_framework='pytest', 
            to_framework='unittest'
        )
        
        assert 'class Test' in unittest_result
        assert 'def test_' in unittest_result
        assert 'self.assertEqual' in unittest_result


class TestContextManager:
    """Test the context management system"""
    
    @pytest.fixture
    def context_manager(self):
        """Create a context manager for testing"""
        return ContextManager()
    
    def test_context_creation(self, context_manager):
        """Test context creation and management"""
        context_id = context_manager.create_context('test_context')
        assert context_id is not None
        assert context_manager.context_exists(context_id)
    
    def test_context_data_storage(self, context_manager):
        """Test storing and retrieving context data"""
        context_id = context_manager.create_context('data_test')
        test_data = {'key': 'value', 'number': 42}
        
        context_manager.set_context_data(context_id, 'test_key', test_data)
        retrieved_data = context_manager.get_context_data(context_id, 'test_key')
        
        assert retrieved_data == test_data
    
    def test_context_isolation(self, context_manager):
        """Test that contexts are properly isolated"""
        context1 = context_manager.create_context('context1')
        context2 = context_manager.create_context('context2')
        
        context_manager.set_context_data(context1, 'key', 'value1')
        context_manager.set_context_data(context2, 'key', 'value2')
        
        assert context_manager.get_context_data(context1, 'key') == 'value1'
        assert context_manager.get_context_data(context2, 'key') == 'value2'
    
    def test_context_cleanup(self, context_manager):
        """Test context cleanup and resource management"""
        context_id = context_manager.create_context('cleanup_test')
        context_manager.set_context_data(context_id, 'resource', 'allocated')
        
        context_manager.cleanup_context(context_id)
        assert not context_manager.context_exists(context_id)
    
    def test_context_inheritance(self, context_manager):
        """Test context inheritance mechanisms"""
        parent_context = context_manager.create_context('parent')
        context_manager.set_context_data(parent_context, 'inherited_key', 'inherited_value')
        
        child_context = context_manager.create_child_context(parent_context, 'child')
        inherited_value = context_manager.get_context_data(child_context, 'inherited_key')
        
        assert inherited_value == 'inherited_value'


class TestSharedState:
    """Test the shared state management system"""
    
    @pytest.fixture
    def shared_state(self):
        """Create a shared state instance for testing"""
        return SharedState()
    
    def test_state_initialization(self, shared_state):
        """Test shared state initialization"""
        assert shared_state is not None
        assert hasattr(shared_state, 'get_state')
        assert hasattr(shared_state, 'set_state')
    
    def test_state_persistence(self, shared_state):
        """Test state persistence across operations"""
        test_state = {
            'test_results': {'passed': 10, 'failed': 2},
            'coverage': 85.5,
            'timestamp': '2025-08-21T19:30:00Z'
        }
        
        shared_state.set_state('test_session', test_state)
        retrieved_state = shared_state.get_state('test_session')
        
        assert retrieved_state == test_state
    
    def test_concurrent_state_access(self, shared_state):
        """Test concurrent access to shared state"""
        import threading
        import time
        
        results = []
        
        def worker(worker_id):
            shared_state.set_state(f'worker_{worker_id}', f'data_{worker_id}')
            time.sleep(0.1)  # Simulate work
            result = shared_state.get_state(f'worker_{worker_id}')
            results.append(result)
        
        threads = [threading.Thread(target=worker, args=[i]) for i in range(5)]
        for thread in threads:
            thread.start()
        for thread in threads:
            thread.join()
        
        assert len(results) == 5
        assert all(f'data_{i}' in results for i in range(5))
    
    def test_state_serialization(self, shared_state):
        """Test state serialization and deserialization"""
        complex_state = {
            'nested': {'deep': {'data': [1, 2, 3]}},
            'functions': 'cannot_serialize',
            'simple': 'string'
        }
        
        shared_state.set_state('complex', complex_state)
        serialized = shared_state.serialize_state('complex')
        
        assert serialized is not None
        assert 'nested' in serialized
    
    def test_state_validation(self, shared_state):
        """Test state validation and error handling"""
        invalid_states = [
            None,
            lambda x: x,  # Function - not serializable
            object(),     # Custom object
        ]
        
        for invalid_state in invalid_states:
            with pytest.raises((TypeError, ValueError)):
                shared_state.set_state('invalid', invalid_state)


class TestTrackingManager:
    """Test the tracking and monitoring system"""
    
    @pytest.fixture
    def tracking_manager(self):
        """Create a tracking manager for testing"""
        return TrackingManager()
    
    def test_event_tracking(self, tracking_manager):
        """Test event tracking functionality"""
        event_data = {
            'event_type': 'test_execution',
            'module': 'test_module.py',
            'duration': 1.5,
            'status': 'passed'
        }
        
        event_id = tracking_manager.track_event(event_data)
        assert event_id is not None
        
        retrieved_event = tracking_manager.get_event(event_id)
        assert retrieved_event['event_type'] == 'test_execution'
    
    def test_metrics_collection(self, tracking_manager):
        """Test metrics collection and aggregation"""
        # Track multiple test events
        for i in range(10):
            tracking_manager.track_event({
                'event_type': 'test_execution',
                'duration': 1.0 + i * 0.1,
                'status': 'passed' if i % 2 == 0 else 'failed'
            })
        
        metrics = tracking_manager.get_metrics('test_execution')
        assert metrics['total_events'] == 10
        assert metrics['average_duration'] > 0
        assert metrics['success_rate'] == 0.5  # 50% pass rate
    
    def test_performance_monitoring(self, tracking_manager):
        """Test performance monitoring capabilities"""
        with tracking_manager.monitor_performance('test_operation') as monitor:
            # Simulate some work
            import time
            time.sleep(0.1)
        
        metrics = tracking_manager.get_performance_metrics('test_operation')
        assert metrics['duration'] >= 0.1
        assert metrics['memory_usage'] > 0
    
    def test_tracking_export(self, tracking_manager):
        """Test tracking data export functionality"""
        # Add some test data
        for i in range(5):
            tracking_manager.track_event({
                'event_type': 'export_test',
                'data': f'test_data_{i}'
            })
        
        exported_data = tracking_manager.export_tracking_data('export_test')
        assert len(exported_data) == 5
        assert all('test_data_' in str(event) for event in exported_data)


class TestFeatureFlags:
    """Test the feature flag management system"""
    
    @pytest.fixture
    def feature_flags(self):
        """Create a feature flags manager for testing"""
        return FeatureFlags()
    
    def test_flag_creation(self, feature_flags):
        """Test creating and managing feature flags"""
        feature_flags.create_flag('test_feature', default_value=False)
        assert feature_flags.is_flag_enabled('test_feature') == False
        
        feature_flags.enable_flag('test_feature')
        assert feature_flags.is_flag_enabled('test_feature') == True
    
    def test_flag_conditions(self, feature_flags):
        """Test conditional feature flag activation"""
        # Create flag with conditions
        conditions = {
            'environment': 'development',
            'user_group': 'beta_testers'
        }
        
        feature_flags.create_flag('conditional_feature', conditions=conditions)
        
        # Test with matching conditions
        context = {'environment': 'development', 'user_group': 'beta_testers'}
        assert feature_flags.is_flag_enabled('conditional_feature', context) == True
        
        # Test with non-matching conditions
        context = {'environment': 'production', 'user_group': 'regular_users'}
        assert feature_flags.is_flag_enabled('conditional_feature', context) == False
    
    def test_flag_rollout_percentage(self, feature_flags):
        """Test percentage-based flag rollouts"""
        feature_flags.create_flag('rollout_feature', rollout_percentage=50)
        
        # Test multiple evaluations to check percentage distribution
        enabled_count = 0
        total_tests = 100
        
        for i in range(total_tests):
            user_id = f'user_{i}'
            if feature_flags.is_flag_enabled('rollout_feature', {'user_id': user_id}):
                enabled_count += 1
        
        # Should be approximately 50% (allow some variance)
        assert 40 <= enabled_count <= 60
    
    def test_flag_persistence(self, feature_flags):
        """Test feature flag persistence across sessions"""
        feature_flags.create_flag('persistent_feature', default_value=True)
        feature_flags.disable_flag('persistent_feature')
        
        # Simulate session restart
        new_feature_flags = FeatureFlags()
        new_feature_flags.load_persisted_flags()
        
        assert new_feature_flags.is_flag_enabled('persistent_feature') == False


class TestUnifiedConfig:
    """Test the unified configuration system"""
    
    @pytest.fixture
    def temp_config_dir(self):
        """Create a temporary directory for config testing"""
        temp_dir = tempfile.mkdtemp()
        yield temp_dir
        shutil.rmtree(temp_dir)
    
    @pytest.fixture
    def unified_config(self, temp_config_dir):
        """Create a unified config instance for testing"""
        return UnifiedConfig(config_dir=temp_config_dir)
    
    def test_config_loading(self, unified_config, temp_config_dir):
        """Test configuration loading from multiple sources"""
        # Create test config files
        json_config = {'database': {'host': 'localhost', 'port': 5432}}
        yaml_config = {'logging': {'level': 'INFO', 'handlers': ['console']}}
        
        with open(os.path.join(temp_config_dir, 'database.json'), 'w') as f:
            json.dump(json_config, f)
        
        # Test loading
        unified_config.load_config()
        
        assert unified_config.get('database.host') == 'localhost'
        assert unified_config.get('database.port') == 5432
    
    def test_config_hierarchical_access(self, unified_config):
        """Test hierarchical configuration access"""
        config_data = {
            'app': {
                'name': 'TestMaster',
                'version': '1.0.0',
                'features': {
                    'security': {'enabled': True},
                    'monitoring': {'enabled': False}
                }
            }
        }
        
        unified_config.set_config(config_data)
        
        assert unified_config.get('app.name') == 'TestMaster'
        assert unified_config.get('app.features.security.enabled') == True
        assert unified_config.get('app.features.monitoring.enabled') == False
    
    def test_config_environment_overrides(self, unified_config):
        """Test environment variable overrides"""
        base_config = {'app': {'debug': False, 'port': 8000}}
        unified_config.set_config(base_config)
        
        # Simulate environment variables
        with patch.dict(os.environ, {'APP_DEBUG': 'true', 'APP_PORT': '9000'}):
            unified_config.apply_environment_overrides()
            
            assert unified_config.get('app.debug') == True
            assert unified_config.get('app.port') == 9000
    
    def test_config_validation(self, unified_config):
        """Test configuration validation"""
        schema = {
            'type': 'object',
            'properties': {
                'database': {
                    'type': 'object',
                    'properties': {
                        'host': {'type': 'string'},
                        'port': {'type': 'integer', 'minimum': 1, 'maximum': 65535}
                    },
                    'required': ['host', 'port']
                }
            },
            'required': ['database']
        }
        
        # Valid config
        valid_config = {'database': {'host': 'localhost', 'port': 5432}}
        assert unified_config.validate_config(valid_config, schema) == True
        
        # Invalid config
        invalid_config = {'database': {'host': 'localhost', 'port': 70000}}
        assert unified_config.validate_config(invalid_config, schema) == False
    
    def test_config_hot_reload(self, unified_config, temp_config_dir):
        """Test hot reloading of configuration changes"""
        config_file = os.path.join(temp_config_dir, 'hot_reload.json')
        initial_config = {'setting': 'initial_value'}
        
        with open(config_file, 'w') as f:
            json.dump(initial_config, f)
        
        unified_config.load_config()
        assert unified_config.get('setting') == 'initial_value'
        
        # Modify config file
        updated_config = {'setting': 'updated_value'}
        with open(config_file, 'w') as f:
            json.dump(updated_config, f)
        
        # Trigger hot reload
        unified_config.reload_config()
        assert unified_config.get('setting') == 'updated_value'


# Utility functions for testing
def mock_open_with_content(content):
    """Create a mock open function that returns specific content"""
    m = MagicMock()
    m.return_value.__enter__.return_value.read.return_value = content
    return m


# Integration tests
class TestCoreIntegration:
    """Test integration between core modules"""
    
    def test_framework_with_context_integration(self):
        """Test framework abstraction with context manager"""
        framework = FrameworkAbstraction()
        context = ContextManager()
        
        # Create context for framework operation
        ctx_id = context.create_context('framework_test')
        context.set_context_data(ctx_id, 'framework', 'pytest')
        
        framework_type = context.get_context_data(ctx_id, 'framework')
        assert framework.is_framework_supported(framework_type)
    
    def test_tracking_with_shared_state_integration(self):
        """Test tracking manager with shared state"""
        tracking = TrackingManager()
        shared_state = SharedState()
        
        # Track event and store in shared state
        event_data = {'type': 'integration_test', 'status': 'success'}
        event_id = tracking.track_event(event_data)
        
        shared_state.set_state('last_event_id', event_id)
        retrieved_id = shared_state.get_state('last_event_id')
        
        assert retrieved_id == event_id
    
    def test_feature_flags_with_config_integration(self):
        """Test feature flags with unified config"""
        config = UnifiedConfig()
        flags = FeatureFlags()
        
        # Set feature flag configuration
        flag_config = {
            'features': {
                'new_testing_engine': {'enabled': True},
                'experimental_coverage': {'enabled': False}
            }
        }
        
        config.set_config(flag_config)
        
        # Apply config to feature flags
        flags.load_from_config(config.get('features'))
        
        assert flags.is_flag_enabled('new_testing_engine') == True
        assert flags.is_flag_enabled('experimental_coverage') == False


if __name__ == "__main__":
    # Run the tests
    pytest.main([__file__, "-v", "--tb=short"])