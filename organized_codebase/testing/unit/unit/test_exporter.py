"""
Test Export System - Advanced test suite export and report generation

This module provides comprehensive export capabilities for generated test suites,
including multiple output formats, detailed reporting, and integration with various
testing frameworks. Supports advanced formatting, optimization, and quality assurance
for exported test files.

Enterprise Features:
- Multi-format test export (pytest, unittest, custom frameworks)
- Advanced code formatting with style compliance
- Comprehensive reporting with metrics and insights
- Quality assurance with test validation and optimization
- Integration with CI/CD pipelines and testing tools
- Extensible export system with custom format support

Key Components:
- TestExporter: Main export engine with format management
- ReportGenerator: Comprehensive report generation with analytics
- CodeFormatter: Advanced code formatting and style compliance
- QualityValidator: Quality assurance and test validation
- IntegrationManager: CI/CD and tool integration support
"""

import json
import csv
from typing import Dict, List, Any, Optional, Set, Tuple, Union, IO
from pathlib import Path
from dataclasses import dataclass, field
from datetime import datetime
from abc import ABC, abstractmethod
import xml.etree.ElementTree as ET
from jinja2 import Template, Environment, FileSystemLoader
import tempfile

from .test_models import (
    TestCase, TestSuite, TestType, ComplexityLevel, GenerationReport,
    CoverageLevel, validate_test_case
)


@dataclass
class ExportConfig:
    """Configuration for test export operations."""
    output_format: str = "pytest"  # pytest, unittest, custom
    include_docstrings: bool = True
    include_type_hints: bool = True
    include_imports: bool = True
    include_setup_teardown: bool = True
    include_fixtures: bool = True
    code_style: str = "pep8"  # pep8, google, numpy
    line_length: int = 88
    indent_size: int = 4
    generate_requirements: bool = True
    generate_config_files: bool = True
    optimize_imports: bool = True
    validate_syntax: bool = True
    include_metadata: bool = True


@dataclass
class ExportResult:
    """Result of test export operation."""
    success: bool
    files_created: List[Path]
    total_tests_exported: int
    export_time_seconds: float
    validation_errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    metrics: Dict[str, Any] = field(default_factory=dict)


class ExportFormatter(ABC):
    """Abstract base class for test export formatters."""
    
    @abstractmethod
    def format_test_suite(self, test_suite: TestSuite, config: ExportConfig) -> str:
        """Format test suite for export."""
        pass
    
    @abstractmethod
    def get_required_imports(self, test_suite: TestSuite) -> List[str]:
        """Get required imports for the test suite."""
        pass
    
    @abstractmethod
    def generate_setup_code(self, test_suite: TestSuite) -> str:
        """Generate setup code for the test framework."""
        pass


class PytestFormatter(ExportFormatter):
    """Pytest format test exporter."""
    
    def format_test_suite(self, test_suite: TestSuite, config: ExportConfig) -> str:
        """Format test suite for pytest."""
        imports = self.get_required_imports(test_suite)
        setup_code = self.generate_setup_code(test_suite) if config.include_setup_teardown else ""
        
        # Group tests by class if needed
        class_name = f"Test{test_suite.module_name.replace('.', '').title()}"
        
        template = f'''"""
Comprehensive tests for {test_suite.module_name}.
Auto-generated by TestMaster Automated Test Generator.

Generated: {test_suite.generation_timestamp.isoformat()}
Target Coverage: {test_suite.estimated_coverage:.1f}%
Test Count: {len(test_suite.test_cases)}
"""

{chr(10).join(imports)}

from {C:.Users.kbass.OneDrive.Documents.testmaster.organized_codebase.testing.unit.test_suite.module_name} import *


class {class_name}:
    """Test class for {test_suite.module_name}."""
    
    def setup_method(self):
        """Setup method called before each test."""
        {setup_code}
    
    def teardown_method(self):
        """Teardown method called after each test."""
        {test_suite.teardown_code}

{self._format_test_cases(test_suite.test_cases, config)}


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
'''
        
        return self._clean_formatting(template, config)
    
    def get_required_imports(self, test_suite: TestSuite) -> List[str]:
        """Get pytest-specific imports."""
        imports = [
            "import pytest",
            "import unittest",
            "from unittest.mock import Mock, patch, MagicMock, AsyncMock",
            "import asyncio",
            "from pathlib import Path",
            "from typing import Any, List, Dict, Optional",
            "from datetime import datetime"
        ]
        
        # Add specific imports based on test requirements
        has_async_tests = any(tc.test_type == TestType.ASYNC for tc in test_suite.test_cases)
        has_mock_tests = any(tc.mock_requirements for tc in test_suite.test_cases)
        has_performance_tests = any(tc.test_type == TestType.PERFORMANCE for tc in test_suite.test_cases)
        
        if has_async_tests:
            imports.append("import asyncio")
        
        if has_mock_tests:
            imports.extend([
                "import requests",
                "import sqlite3",
                "from unittest.mock import mock_open"
            ])
        
        if has_performance_tests:
            imports.extend([
                "import time",
                "import psutil",
                "import memory_profiler"
            ])
        
        return imports
    
    def generate_setup_code(self, test_suite: TestSuite) -> str:
        """Generate pytest setup code."""
        return test_suite.setup_code or '"""Setup for test class."""\npass'
    
    def _format_test_cases(self, test_cases: List[TestCase], config: ExportConfig) -> str:
        """Format individual test cases."""
        formatted_tests = []
        
        for test_case in test_cases:
            # Add metadata comments if enabled
            if config.include_metadata:
                metadata = f'''
    # Test Metadata:
    # Type: {test_case.test_type.value}
    # Complexity: {test_case.complexity_score.name}
    # Coverage: {test_case.coverage_increase}%
    # Priority: {test_case.priority}
    # Target: {test_case.target_function}'''
                formatted_tests.append(metadata)
            
            # Format test code
            formatted_tests.append(test_case.code)
        
        return '\n'.join(formatted_tests)
    
    def _clean_formatting(self, code: str, config: ExportConfig) -> str:
        """Clean and format code according to style guide."""
        lines = code.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # Remove trailing whitespace
            line = line.rstrip()
            
            # Ensure proper indentation
            if line.strip():
                # Maintain existing indentation structure
                cleaned_lines.append(line)
            elif cleaned_lines and cleaned_lines[-1].strip():
                # Keep single blank lines between sections
                cleaned_lines.append('')
        
        return '\n'.join(cleaned_lines)


class UnittestFormatter(ExportFormatter):
    """Unittest format test exporter."""
    
    def format_test_suite(self, test_suite: TestSuite, config: ExportConfig) -> str:
        """Format test suite for unittest."""
        imports = self.get_required_imports(test_suite)
        class_name = f"Test{test_suite.module_name.replace('.', '').title()}"
        
        template = f'''"""
Comprehensive tests for {test_suite.module_name}.
Auto-generated by TestMaster Automated Test Generator.
"""

{chr(10).join(imports)}

from {test_suite.module_name} import *


class {class_name}(unittest.TestCase):
    """Test class for {test_suite.module_name}."""
    
    def setUp(self):
        """Setup method called before each test."""
        {test_suite.setup_code}
    
    def tearDown(self):
        """Teardown method called after each test."""
        {test_suite.teardown_code}

{self._format_unittest_cases(test_suite.test_cases, config)}


if __name__ == "__main__":
    unittest.main()
'''
        
        return template
    
    def get_required_imports(self, test_suite: TestSuite) -> List[str]:
        """Get unittest-specific imports."""
        return [
            "import unittest",
            "from unittest.mock import Mock, patch, MagicMock",
            "from pathlib import Path",
            "from typing import Any, List, Dict, Optional"
        ]
    
    def generate_setup_code(self, test_suite: TestSuite) -> str:
        """Generate unittest setup code."""
        return test_suite.setup_code or 'pass'
    
    def _format_unittest_cases(self, test_cases: List[TestCase], config: ExportConfig) -> str:
        """Format test cases for unittest."""
        formatted_tests = []
        
        for test_case in test_cases:
            # Convert pytest-style to unittest-style
            unittest_code = test_case.code.replace('assert ', 'self.assert')
            unittest_code = unittest_code.replace('pytest.raises', 'self.assertRaises')
            unittest_code = unittest_code.replace('@pytest.mark.asyncio', '')
            
            formatted_tests.append(unittest_code)
        
        return '\n'.join(formatted_tests)


class ReportGenerator:
    """Generate comprehensive reports for test generation and export."""
    
    def __init__(self):
        self.template_env = Environment(loader=FileSystemLoader('.'))
    
    def generate_html_report(self, 
                           test_suites: Dict[str, TestSuite],
                           generation_report: GenerationReport,
                           output_path: Path) -> Path:
        """
        Generate comprehensive HTML report.
        
        Args:
            test_suites: Generated test suites
            generation_report: Generation metrics and results
            output_path: Path for output file
            
        Returns:
            Path to generated report file
        """
        report_data = self._prepare_report_data(test_suites, generation_report)
        
        html_template = '''
<!DOCTYPE html>
<html>
<head>
    <title>TestMaster Test Generation Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .header { background-color: #f0f0f0; padding: 20px; margin-bottom: 20px; }
        .metric { display: inline-block; margin: 10px; padding: 10px; background-color: #e9ecef; }
        .module { border: 1px solid #ccc; margin: 10px 0; padding: 15px; }
        .test-type { color: #007bff; font-weight: bold; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
    </style>
</head>
<body>
    <div class="header">
        <h1>TestMaster Test Generation Report</h1>
        <p>Generated: {{ report_data.timestamp }}</p>
    </div>
    
    <div class="metrics">
        <h2>Summary Metrics</h2>
        <div class="metric">
            <strong>Total Modules:</strong> {{ report_data.total_modules }}
        </div>
        <div class="metric">
            <strong>Total Tests:</strong> {{ report_data.total_tests }}
        </div>
        <div class="metric">
            <strong>Average Coverage:</strong> {{ report_data.average_coverage }}%
        </div>
        <div class="metric">
            <strong>Generation Time:</strong> {{ report_data.generation_time }}s
        </div>
    </div>
    
    <div class="modules">
        <h2>Module Details</h2>
        {% for module in report_data.modules %}
        <div class="module">
            <h3>{{ module.name }}</h3>
            <p><strong>Tests:</strong> {{ module.test_count }} | 
               <strong>Coverage:</strong> {{ module.coverage }}% |
               <strong>Complexity:</strong> {{ module.complexity }}</p>
            
            <h4>Test Type Distribution</h4>
            <table>
                <tr><th>Test Type</th><th>Count</th><th>Coverage</th></tr>
                {% for test_type in module.test_types %}
                <tr>
                    <td class="test-type">{{ test_type.name }}</td>
                    <td>{{ test_type.count }}</td>
                    <td>{{ test_type.coverage }}%</td>
                </tr>
                {% endfor %}
            </table>
        </div>
        {% endfor %}
    </div>
</body>
</html>
'''
        
        template = Template(html_template)
        html_content = template.render(report_data=report_data)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return output_path
    
    def generate_json_report(self,
                           test_suites: Dict[str, TestSuite],
                           generation_report: GenerationReport,
                           output_path: Path) -> Path:
        """Generate JSON report for programmatic consumption."""
        report_data = self._prepare_report_data(test_suites, generation_report)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, default=str)
        
        return output_path
    
    def generate_csv_report(self,
                          test_suites: Dict[str, TestSuite],
                          output_path: Path) -> Path:
        """Generate CSV report for data analysis."""
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # Write header
            writer.writerow([
                'Module', 'Test Name', 'Test Type', 'Complexity', 
                'Coverage', 'Priority', 'Target Function'
            ])
            
            # Write test data
            for module_name, test_suite in test_suites.items():
                for test_case in test_suite.test_cases:
                    writer.writerow([
                        module_name,
                        test_case.name,
                        test_case.test_type.value,
                        test_case.complexity_score.name,
                        test_case.coverage_increase,
                        test_case.priority,
                        test_case.target_function
                    ])
        
        return output_path
    
    def _prepare_report_data(self, 
                           test_suites: Dict[str, TestSuite],
                           generation_report: GenerationReport) -> Dict[str, Any]:
        """Prepare data for report generation."""
        total_tests = sum(len(suite.test_cases) for suite in test_suites.values())
        total_coverage = sum(suite.estimated_coverage for suite in test_suites.values())
        average_coverage = total_coverage / len(test_suites) if test_suites else 0
        
        modules_data = []
        for module_name, test_suite in test_suites.items():
            test_type_dist = {}
            for test_case in test_suite.test_cases:
                test_type = test_case.test_type.value
                if test_type not in test_type_dist:
                    test_type_dist[test_type] = {'count': 0, 'coverage': 0}
                test_type_dist[test_type]['count'] += 1
                test_type_dist[test_type]['coverage'] += test_case.coverage_increase
            
            modules_data.append({
                'name': module_name,
                'test_count': len(test_suite.test_cases),
                'coverage': test_suite.estimated_coverage,
                'complexity': test_suite.average_complexity,
                'test_types': [
                    {
                        'name': test_type,
                        'count': data['count'],
                        'coverage': data['coverage'] / data['count'] if data['count'] > 0 else 0
                    }
                    for test_type, data in test_type_dist.items()
                ]
            })
        
        return {
            'timestamp': datetime.now().isoformat(),
            'total_modules': len(test_suites),
            'total_tests': total_tests,
            'average_coverage': f"{average_coverage:.1f}",
            'generation_time': f"{generation_report.generation_time_seconds:.2f}",
            'modules': modules_data
        }


class QualityValidator:
    """Quality assurance and validation for exported tests."""
    
    def validate_test_suite(self, test_suite: TestSuite) -> List[str]:
        """Validate test suite quality and structure."""
        errors = []
        
        # Validate individual test cases
        for test_case in test_suite.test_cases:
            test_errors = validate_test_case(test_case)
            errors.extend([f"{test_case.name}: {error}" for error in test_errors])
        
        # Check test coverage
        if test_suite.estimated_coverage < 60:
            errors.append(f"Low test coverage: {test_suite.estimated_coverage:.1f}% (minimum 60%)")
        
        # Check test distribution
        test_types = [tc.test_type for tc in test_suite.test_cases]
        if TestType.UNIT not in test_types:
            errors.append("Missing unit tests")
        
        # Check for duplicate tests
        test_names = [tc.name for tc in test_suite.test_cases]
        duplicates = set([name for name in test_names if test_names.count(name) > 1])
        if duplicates:
            errors.append(f"Duplicate test names: {', '.join(duplicates)}")
        
        return errors
    
    def validate_syntax(self, code: str) -> List[str]:
        """Validate Python syntax of generated code."""
        errors = []
        
        try:
            compile(code, '<string>', 'exec')
        except SyntaxError as e:
            errors.append(f"Syntax error at line {e.lineno}: {e.msg}")
        except Exception as e:
            errors.append(f"Compilation error: {str(e)}")
        
        return errors


class TestExporter:
    """
    Main test export engine with multi-format support.
    
    Provides comprehensive export capabilities for generated test suites
    with advanced formatting, validation, and reporting features.
    """
    
    def __init__(self, config: ExportConfig = None):
        self.config = config or ExportConfig()
        self.formatters = {
            'pytest': PytestFormatter(),
            'unittest': UnittestFormatter()
        }
        self.report_generator = ReportGenerator()
        self.validator = QualityValidator()
    
    def export_test_suite(self, 
                         test_suite: TestSuite,
                         output_path: Path,
                         validate: bool = True) -> ExportResult:
        """
        Export a single test suite to file.
        
        Args:
            test_suite: Test suite to export
            output_path: Path for output file
            validate: Whether to validate before export
            
        Returns:
            Export result with metrics and status
        """
        start_time = datetime.now()
        errors = []
        warnings = []
        
        try:
            # Validate test suite if requested
            if validate:
                validation_errors = self.validator.validate_test_suite(test_suite)
                if validation_errors:
                    errors.extend(validation_errors)
                    if not self.config.validate_syntax:  # Continue despite validation errors
                        return ExportResult(
                            success=False,
                            files_created=[],
                            total_tests_exported=0,
                            export_time_seconds=0,
                            validation_errors=errors
                        )
            
            # Get appropriate formatter
            formatter = self.formatters.get(self.config.output_format)
            if not formatter:
                raise ValueError(f"Unsupported output format: {self.config.output_format}")
            
            # Format test suite
            formatted_code = formatter.format_test_suite(test_suite, self.config)
            
            # Validate syntax if enabled
            if self.config.validate_syntax:
                syntax_errors = self.validator.validate_syntax(formatted_code)
                if syntax_errors:
                    errors.extend(syntax_errors)
            
            # Ensure output directory exists
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Write test file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(formatted_code)
            
            # Generate additional files if configured
            additional_files = self._generate_additional_files(test_suite, output_path.parent)
            
            # Calculate metrics
            export_time = (datetime.now() - start_time).total_seconds()
            
            return ExportResult(
                success=len(errors) == 0,
                files_created=[output_path] + additional_files,
                total_tests_exported=len(test_suite.test_cases),
                export_time_seconds=export_time,
                validation_errors=errors,
                warnings=warnings,
                metrics={
                    'estimated_coverage': test_suite.estimated_coverage,
                    'test_count': len(test_suite.test_cases),
                    'complexity_average': test_suite.average_complexity
                }
            )
            
        except Exception as e:
            return ExportResult(
                success=False,
                files_created=[],
                total_tests_exported=0,
                export_time_seconds=(datetime.now() - start_time).total_seconds(),
                validation_errors=[str(e)]
            )
    
    def export_multiple_suites(self,
                              test_suites: Dict[str, TestSuite],
                              output_dir: Path,
                              generate_reports: bool = True) -> Dict[str, ExportResult]:
        """
        Export multiple test suites with comprehensive reporting.
        
        Args:
            test_suites: Dictionary of test suites to export
            output_dir: Output directory for test files
            generate_reports: Whether to generate reports
            
        Returns:
            Dictionary mapping module names to export results
        """
        results = {}
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Export individual test suites
        for module_name, test_suite in test_suites.items():
            test_filename = f"test_{module_name.replace('.', '_')}_generated.py"
            test_file_path = output_dir / test_filename
            
            result = self.export_test_suite(test_suite, test_file_path)
            results[module_name] = result
        
        # Generate comprehensive reports if requested
        if generate_reports:
            self._generate_comprehensive_reports(test_suites, output_dir, results)
        
        return results
    
    def _generate_additional_files(self, test_suite: TestSuite, output_dir: Path) -> List[Path]:
        """Generate additional configuration and requirement files."""
        additional_files = []
        
        if self.config.generate_requirements:
            requirements_path = output_dir / "requirements-test.txt"
            self._generate_requirements_file(test_suite, requirements_path)
            additional_files.append(requirements_path)
        
        if self.config.generate_config_files:
            if self.config.output_format == "pytest":
                pytest_config_path = output_dir / "pytest.ini"
                self._generate_pytest_config(pytest_config_path)
                additional_files.append(pytest_config_path)
        
        return additional_files
    
    def _generate_requirements_file(self, test_suite: TestSuite, output_path: Path):
        """Generate requirements.txt for test dependencies."""
        requirements = ["pytest>=7.0.0", "pytest-asyncio>=0.21.0"]
        
        # Add requirements based on test characteristics
        has_mock_tests = any(tc.mock_requirements for tc in test_suite.test_cases)
        has_performance_tests = any(tc.test_type == TestType.PERFORMANCE for tc in test_suite.test_cases)
        
        if has_mock_tests:
            requirements.extend(["requests>=2.28.0", "responses>=0.22.0"])
        
        if has_performance_tests:
            requirements.extend(["psutil>=5.9.0", "memory-profiler>=0.60.0"])
        
        with open(output_path, 'w') as f:
            f.write('\n'.join(requirements))
    
    def _generate_pytest_config(self, output_path: Path):
        """Generate pytest.ini configuration file."""
        config_content = """
[tool:pytest]
testpaths = .
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --cov-report=html
    --cov-report=term-missing
markers =
    unit: Unit tests
    integration: Integration tests
    performance: Performance tests
    slow: Slow running tests
"""
        
        with open(output_path, 'w') as f:
            f.write(config_content.strip())
    
    def _generate_comprehensive_reports(self,
                                      test_suites: Dict[str, TestSuite],
                                      output_dir: Path,
                                      export_results: Dict[str, ExportResult]):
        """Generate comprehensive reports for all exported test suites."""
        # Create generation report
        total_tests = sum(len(suite.test_cases) for suite in test_suites.values())
        total_time = sum(result.export_time_seconds for result in export_results.values())
        
        generation_report = GenerationReport(
            total_modules_processed=len(test_suites),
            total_tests_generated=total_tests,
            total_coverage_estimated=sum(suite.estimated_coverage for suite in test_suites.values()) / len(test_suites),
            generation_time_seconds=total_time,
            modules_processed=list(test_suites.keys()),
            test_files_created=[str(f) for result in export_results.values() for f in result.files_created],
            coverage_by_module={name: suite.estimated_coverage for name, suite in test_suites.items()},
            test_distribution={},  # Would calculate actual distribution
            complexity_distribution={},  # Would calculate actual distribution
            errors_encountered=[],
            warnings=[],
            recommendations=[]
        )
        
        # Generate reports
        reports_dir = output_dir / "reports"
        reports_dir.mkdir(exist_ok=True)
        
        self.report_generator.generate_html_report(
            test_suites, generation_report, reports_dir / "test_generation_report.html"
        )
        
        self.report_generator.generate_json_report(
            test_suites, generation_report, reports_dir / "test_generation_report.json"
        )
        
        self.report_generator.generate_csv_report(
            test_suites, reports_dir / "test_generation_report.csv"
        )
    
    def add_custom_formatter(self, name: str, formatter: ExportFormatter):
        """Add a custom export formatter."""
        self.formatters[name] = formatter


# Factory Functions

def create_test_exporter(config: ExportConfig = None) -> TestExporter:
    """
    Create a test exporter with configuration.
    
    Args:
        config: Optional export configuration
        
    Returns:
        Configured TestExporter instance
    """
    return TestExporter(config)


def create_export_config(**kwargs) -> ExportConfig:
    """
    Create export configuration with custom settings.
    
    Args:
        **kwargs: Configuration parameters
        
    Returns:
        Configured ExportConfig instance
    """
    return ExportConfig(**kwargs)


# Utility Functions

def export_test_suite_to_file(test_suite: TestSuite,
                             output_path: Path,
                             format_type: str = "pytest") -> bool:
    """
    Convenience function to export a test suite to file.
    
    Args:
        test_suite: Test suite to export
        output_path: Path for output file
        format_type: Export format (pytest, unittest)
        
    Returns:
        True if export successful, False otherwise
    """
    config = create_export_config(output_format=format_type)
    exporter = create_test_exporter(config)
    
    result = exporter.export_test_suite(test_suite, output_path)
    return result.success


def validate_exported_tests(test_file_path: Path) -> List[str]:
    """
    Validate exported test file.
    
    Args:
        test_file_path: Path to test file
        
    Returns:
        List of validation errors (empty if valid)
    """
    validator = QualityValidator()
    
    try:
        with open(test_file_path, 'r', encoding='utf-8') as f:
            code = f.read()
        
        return validator.validate_syntax(code)
    except Exception as e:
        return [f"Error reading file: {str(e)}"]


# Version information
__version__ = '1.0.0'
__author__ = 'TestMaster Export System Team'
__description__ = 'Advanced test suite export and report generation system'